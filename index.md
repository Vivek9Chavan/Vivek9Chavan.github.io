---
layout: default
title: Vivek Chavan
---

# ğŸ‘‹ Hello!


<div style="display: flex; align-items: flex-start; gap: 40px; flex-wrap: wrap;">

  <!-- Bigger photo column -->
  <div style="flex: 1; min-width: 400px; max-width: 500px;">
    <img src="https://github.com/user-attachments/assets/0c18923f-6d38-4312-ae43-9f4e4c7764ad" 
         alt="Vivek_01" 
         style="width: 100%; height: auto; border-radius: 12px;">
  </div>

  <div style="flex: 2; min-width: 300px;">
    <h2>ğŸ”¬ About Me</h2>
    <p>
      I am an AI Researcher and Computer Vision Scientist developing intelligent systems that can understand and operate in complex, real-world human environments. My work focuses on bridging the gap between foundational research and practical, industry-relevant applications.
    </p>

    <p style="margin: 0.5em 0 1em;">
      <a href="https://scholar.google.com/citations?user=jeREfqcAAAAJ&hl=en" target="_blank" rel="noopener">ğŸ“ Google Scholar</a>
      â€¢ <a href="https://www.linkedin.com/in/vivek9chavan/" target="_blank" rel="noopener">ğŸ’¼ LinkedIn</a>
      â€¢ <a href="https://x.com/vivek9chavan" target="_blank" rel="noopener">ğ• / Twitter</a>
    </p>

    <ul>
      <li>ğŸ­ Industrial Automation</li>
      <li>ğŸ¥ Egocentric AI</li>
      <li>ğŸ“‰ Data Efficiency</li>
      <li>ğŸ§  Continual Learning</li>
      <li>ğŸ”€ Multimodality</li>
      <li>ğŸ¤– Robotics</li>
    </ul>
  </div>

</div>

<hr style="margin: 2em 0;" />

## ğŸ¤ Talks, Presentations & Activities

<ul>
    <li>
    ğŸ† <strong>Winner â€” Food Waste Detection Hackathon</strong><br />
    Participated in and won a hackathon on food waste detection using Computer Vision & AI,  
    sponsored by Voxel51 at Hasso Plattner Institute â€” <em>August 2025</em>
  </li>
  <br />
  
  <li>
    <strong>Talk at Sorbonne University</strong><br />
    <em>Developing Industrial Egocentric Assistants: Integrating Continual Learning, Data Management, and Multimodal Understanding</em><br />
    Center for Artificial Intelligence, Paris â€” <em>April 2025</em>
  </li>
  <br />

  <li>
    <strong>Podcast Interview â€” Heise Online (KI-Update)</strong><br />
    Topic: Current research in Industrial AI and Egocentric Vision<br />
    KI-Update Deep-Dive: â€œAI glasses in industryâ€ â€” <em>29 March 2025</em><br />
    ğŸ”— <a href="https://www.heise.de/news/KI-Update-Deep-Dive-KI-Brillen-helfen-in-der-Industrie-9670746.html" target="_blank" rel="noopener">Heise Online</a>
  </li>
  <br />

  <li>
    <strong>Berlin Science Week â€” Invited Research Talk & Demo</strong><br />
    Public presentation of ongoing research â€” <em>November 2024</em>
  </li>
  <br />

  <li>
    <strong>Science Slam Hamburg â€” Winner</strong><br />
    Top-rated talk (â‰ˆ200 audience) on Artificial Intelligence â€” <em>July 2024</em>
  </li>
  <br />

  <li>
    <strong>Control Trade Fair â€” Technology Demonstration</strong><br />
    Represented the Machine Vision team with live demos (anomaly detection, object detection, egocentric vision).<br />
    Stuttgart â€” <em>April 2024</em>
  </li>
  <br />

  <li>
    <strong>Fraunhofer Vision Session â€” Technical Talk</strong><br />
    Industrial continual learning with a focus on energy consumption and computational footprint â€” <em>November 2023</em>
  </li>
  <br />

  <li>
    <strong>VisionRead Talks â€” Internal Knowledge-Sharing</strong><br />
    Six talks covering recent research in Computer Vision & AI â€” <em>2023â€“2024</em>
  </li>
  <br />

  <li>
    ğŸ† <strong>Winner â€” AI Grid Hackathon</strong><br />
    Developed novel solutions for sustainable AI in industry during an international hackathon challenge â€” <em>September 2024</em>
  </li>
  <br />

  <li>
    ğŸ›  <strong>Workshop Participation</strong><br />
    Attended and contributed to AI Grid Summer School workshops on computer vision, time series forecasting, and prompt engineering â€” <em>September 2024</em>
  </li>
  <br />


</ul>

<hr style="margin: 2em 0;" />

# ğŸ“„ First-Author Publications

<ul>
  <li>
    <strong>Chavan, V.</strong>, Imgrund, Y., Dao, T., Bai, S., Wang, B., Lu, Z., Heimann, O., & KrÃ¼ger, J. (2025).<br />
    <em>IndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants</em>.<br />
    In: <strong>Advances in Neural Information Processing Systems (NeurIPS 2025)</strong>.<br />
    ğŸ”— <a href="https://neurips.cc/virtual/2025/poster/121501" target="_blank" rel="noopener">Conference Page</a>
  </li>
  <br />

  <li>
    <strong>Chavan, V.</strong>, Cenaj, A., Shen, S., Bar, A., Binwani, S., Del Becaro, T., Funk, M., Greschner, L., Hung, R., Klein, S., Kleiner, R., Krause, S., Olbrych, S., Parmar, V., Sarafraz, J., Soroko, D., Withanage Don, D., Zhou, C., Vu, H.T.D., Semnani, P., Weinhardt, D., AndrÃ©, E., KrÃ¼ger, J., & Fresquet, X. (2025).<br />
    <em>Feeling Machines: Ethics, Culture, and the Rise of Emotional AI</em>.<br />
    <strong>arXiv preprint</strong>.<br />
    ğŸ”— <a href="https://arxiv.org/abs/2506.12437" target="_blank" rel="noopener">arXiv</a>
  </li>
  <br />

  <li>
    <strong>Chavan, V.</strong>, Heimann, O., & KrÃ¼ger, J. (2024).<br />
    <em>On the Application of Egocentric Computer Vision to Industrial Inspection</em>.<br />
    In: <strong>ECCV 2024 Workshops</strong>.<br />
    ğŸ”— <a href="https://link.springer.com/chapter/10.1007/978-3-031-92805-5_1" target="_blank" rel="noopener">Springer Link</a>
  </li>
  <br />

  <li>
    <strong>Chavan, V.</strong>, Heimann, O., & KrÃ¼ger, J. (2024).<br />
    <em>A System 1 and System 2 Perspective on Continual Learning for Practical Implementation</em>.<br />
    In: <strong>ECCV 2024 Workshops</strong>.<br />
    ğŸ”— <a href="https://link.springer.com/chapter/10.1007/978-3-031-91578-9_25" target="_blank" rel="noopener">Springer Link</a>
  </li>
  <br />

  <li>
    <strong>Chavan, V.</strong>, Koch, P., SchlÃ¼ter, M., Briese, C., & KrÃ¼ger, J. (2024).<br />
    <em>Active Data Collection and Management for Real-World Continual Learning via Pretrained Oracle</em>.<br />
    In: <strong>CVPR 2024 Workshops</strong>.<br />
    ğŸ”— <a href="https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Chavan_Active_Data_Collection_and_Management_for_Real-World_Continual_Learning_via_CVPRW_2024_paper.html" target="_blank" rel="noopener">CVPR OpenAccess</a>
  </li>
  <br />

  <li>
    <strong>Chavan, V.</strong>, Koch, P., SchlÃ¼ter, M., & Briese, C. (2023).<br />
    <em>Towards Realistic Evaluation of Industrial Continual Learning Scenarios with an Emphasis on Energy Consumption and Computational Footprint</em>.<br />
    In: <strong>ICCV 2023</strong>.<br />
    ğŸ”— <a href="https://www.computer.org/csdl/proceedings-article/iccv/2023/071800l1472/1TJiKOmxmJG" target="_blank" rel="noopener">IEEE Xplore</a>
  </li>
</ul>

<hr style="margin: 2em 0;" />

## ğŸ’¿ Datasets

<ul>
  <li>
    <strong>IndEgo</strong> â€” Coming soon  
    <br />
    A large-scale dataset of industrial scenarios and collaborative work for egocentric assistants.  
  </li>
  <br />

  <li>
    <strong>InVar-100</strong>  
    <br />
    A dataset of industrial objects in varied contexts.  
    ğŸ”— <a href="https://huggingface.co/datasets/vivek9chavan/InVar-100" target="_blank" rel="noopener">Hugging Face</a>
  </li>
</ul>
